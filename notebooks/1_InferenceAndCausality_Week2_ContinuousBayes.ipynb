{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess the Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46979e2b4dbe4900a548a71542793f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='Heads', max=10), IntSlider(value=5, description='Tosses'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Week 2 — From Discrete to Continuous Bayes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "from ipywidgets import interact, IntSlider\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "# --- Parameters ---\n",
    "# prior parameters (Beta distribution)\n",
    "a_prior, b_prior = 2, 2   # \"probably fair\" — centered around 0.5\n",
    "\n",
    "# --- Helper function ---\n",
    "def plot_posterior(heads=0, tosses=0):\n",
    "    \"\"\"\n",
    "    Plot prior, likelihood (up to scale), and posterior for given data.\n",
    "    heads: number of observed heads\n",
    "    tosses: total number of coin tosses\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, 1, 400)\n",
    "    \n",
    "    # prior Beta(a,b)\n",
    "    prior = beta.pdf(x, a_prior, b_prior)\n",
    "    \n",
    "    # posterior Beta(a+a_prior, b+b_prior)\n",
    "    a_post = a_prior + heads\n",
    "    b_post = b_prior + tosses - heads\n",
    "    posterior = beta.pdf(x, a_post, b_post)\n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(x, prior, \"--\", label=f\"Prior Beta({a_prior},{b_prior})\")\n",
    "    plt.plot(x, posterior, label=f\"Posterior Beta({a_post},{b_post})\")\n",
    "    plt.fill_between(x, posterior, alpha=0.2)\n",
    "    plt.xlabel(\"Coin bias θ (probability of heads)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"{heads} heads out of {tosses} tosses\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive widget ---\n",
    "interact(plot_posterior,\n",
    "         heads=IntSlider(min=0, max=10, step=1, value=4, description=\"Heads\"),\n",
    "         tosses=IntSlider(min=1, max=10, step=1, value=5, description=\"Tosses\"));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Exercise\n",
    "Play with the sliders until you find a situation where your prior and data disagree.\n",
    "- Describe what happens to the posterior.\n",
    "- Why doesn’t it completely ignore your prior after only a few tosses?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat happens to the posterior when prior and data disagree?\\n\\nWhen the prior and data disagree, the posterior acts as a weighted compromise between them. For example, if the prior Beta(2,2) suggests a fair coin (θ ≈ 0.5) but we observe extreme data like 0 heads out of 10 tosses, the posterior will shift toward the data but won\\'t fully reach it. The posterior Beta distribution will have its peak between the prior\\'s center (0.5) and the maximum likelihood estimate from the data (0.0 in this case), reflecting uncertainty from limited observations.\\n\\nWhy doesn\\'t it completely ignore the prior after only a few tosses?\\n\\nBayesian inference combines prior beliefs and observed data, weighting them by their relative strengths. The prior Beta(2,2) is equivalent to having already observed 2 heads and 2 tails (4 \"pseudo-observations\"). With only a few tosses (max 10 in the widget), the prior\\'s weight (effectively 4 observations) is still significant relative to the new data. The posterior parameters are additive: a_post = a_prior + heads, so the prior\\'s contribution persists. As more data accumulates, its influence gradually outweighs the prior, but with sparse data, the prior anchors the posterior, preventing overconfident conclusions from limited evidence.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What happens to the posterior when prior and data disagree?\n",
    "\n",
    "When the prior and data disagree, the posterior acts as a weighted compromise between them. For example, if the prior Beta(2,2) suggests a fair coin (θ ≈ 0.5) but we observe extreme data like 0 heads out of 10 tosses, the posterior will shift toward the data but won't fully reach it. The posterior Beta distribution will have its peak between the prior's center (0.5) and the maximum likelihood estimate from the data (0.0 in this case), reflecting uncertainty from limited observations.\n",
    "\n",
    "Why doesn't it completely ignore the prior after only a few tosses?\n",
    "\n",
    "Bayesian inference combines prior beliefs and observed data, weighting them by their relative strengths. The prior Beta(2,2) is equivalent to having already observed 2 heads and 2 tails (4 \"pseudo-observations\"). With only a few tosses (max 10 in the widget), the prior's weight (effectively 4 observations) is still significant relative to the new data. The posterior parameters are additive: a_post = a_prior + heads, so the prior's contribution persists. As more data accumulates, its influence gradually outweighs the prior, but with sparse data, the prior anchors the posterior, preventing overconfident conclusions from limited evidence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
